{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giannisgian/Teliki-ergasia/blob/main/Ukraine_Russia_hashtag1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHS9VH-cyL7m",
        "outputId": "ff9a70a9-1e3b-481f-a9f6-31b47006b82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Twython in /usr/local/lib/python3.7/dist-packages (3.9.1)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from Twython) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from Twython) (1.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->Twython) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->Twython) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Twython\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from twython import Twython\n",
        "from twython import TwythonError\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import ast\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "CONSUMER_KEY = \"DyoTjohC4arsxLFBjmh71l5Fi\"\n",
        "CONSUMER_SECRET = \"sWE3WV27dOOsZnRpSo19bZCojZykVqftYh1uAQvCwqviro4jT1\"\n",
        "OAUTH_TOKEN = \"1133494860554604545-aQrvZDpNyxgi6MwQbHegX8Bkx6CUfI\"\n",
        "OAUTH_TOKEN_SECRET = \"inqueIKTVIqqKGXKiHS7dOwNvSmCQdWgYN83ih1kQkNkS\"\n",
        "twitter = Twython(\n",
        "    CONSUMER_KEY, CONSUMER_SECRET,\n",
        "    OAUTH_TOKEN, OAUTH_TOKEN_SECRET)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96POgbJ3kNWk"
      },
      "source": [
        "#  #Ουκρανία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgeLQW5kyONq"
      },
      "outputs": [],
      "source": [
        "tweets = []\n",
        "MAX_ATTEMPTS = 50\n",
        "COUNT_OF_TWEETS_TO_BE_FETCHED = 10000 \n",
        "\n",
        "for i in range(0,MAX_ATTEMPTS):\n",
        "\n",
        "    if(COUNT_OF_TWEETS_TO_BE_FETCHED < len(tweets)):\n",
        "        print(\"We Got \", len(tweets), \" tweets!!!\")\n",
        "        break # we got the  tweets... !!\n",
        "\n",
        "    #----------------------------------------------------------------#\n",
        "    # STEP 1: Query Twitter\n",
        "    # STEP 2: Save the returned tweets\n",
        "    # STEP 3: Get the next max_id\n",
        "    #----------------------------------------------------------------#\n",
        "\n",
        "    # STEP 1: Query Twitter\n",
        "    if(0 == i):\n",
        "        # Query twitter for data. \n",
        "        results = twitter.search(q=\"ουκρανία\",count='100')\n",
        "        print(\"I Got:\", len(results['statuses']), \" tweets\")\n",
        "    else:\n",
        "        # After the first call we should have max_id from result of previous call. Pass it in query.\n",
        "        results = twitter.search(q=\"ουκρανία\",count='100', include_entities='true',max_id=next_max_id)\n",
        "        print(\"I Got:\", len(results['statuses']), \" tweets\")\n",
        "\n",
        "\n",
        "    # STEP 2: Save the returned tweets\n",
        "    for result in results['statuses']:\n",
        "#        tweet_text = result['text']\n",
        "        tweets.append(result)\n",
        "\n",
        "\n",
        "    # STEP 3: Get the next max_id\n",
        "    try:\n",
        "        # Parse the data returned to get max_id to be passed in consequent call.\n",
        "        next_results_url_params = results['search_metadata']['next_results']\n",
        "        next_max_id = next_results_url_params.split('max_id=')[1].split('&')[0]\n",
        "    except:\n",
        "        # No more next pages\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9UMgSLPyY5O"
      },
      "outputs": [],
      "source": [
        "#results['search_metadata']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDLl2B_Lya0y"
      },
      "outputs": [],
      "source": [
        "#results['statuses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7Jv36zzycyc"
      },
      "outputs": [],
      "source": [
        "Uk_df = pd.DataFrame(tweets)\n",
        "Uk_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kFmuCMoyh_T"
      },
      "outputs": [],
      "source": [
        "# Number of tweets the user has made\n",
        "print(\"I got :\", len(Uk_df), \" in total!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGvSq_dGykSF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9S_sbS4GyoKP"
      },
      "outputs": [],
      "source": [
        "Uk_df.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/Ουκρανία_tweet.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaYGb8jQyybA"
      },
      "source": [
        "# Νέα ενότητα #Ουκρανία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UycRCm_y7vi"
      },
      "outputs": [],
      "source": [
        "Uk = Uk_df[['created_at','text' ]]\n",
        "Uk = Uk.rename(columns={'created_at': 'date'} )\n",
        "Uk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ET8ozxZ6y8KC"
      },
      "outputs": [],
      "source": [
        "Uk.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O24gvWDyzHH9"
      },
      "outputs": [],
      "source": [
        "Uk['year'] = pd.DatetimeIndex(Uk['date']).year\n",
        "Uk['month'] = pd.DatetimeIndex(Uk['date']).month\n",
        "Uk['day'] = pd.DatetimeIndex(Uk['date']).day\n",
        "Uk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJDk0ubYzHey"
      },
      "outputs": [],
      "source": [
        "Uk['text'] = Uk['text'].str.replace(r'https?:\\/\\/.*[\\r\\n]*',\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aM9H5XzNzSF_"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQ7ezthUzT-0"
      },
      "outputs": [],
      "source": [
        "Uk[Uk['year']==2022]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG6ZM7qwzWzm"
      },
      "outputs": [],
      "source": [
        "# Ισως καποτε χρειαστεί να αφαιρέσουμε τους τόνους.....\n",
        "text = Uk['text'].str.replace('ά','α').str.replace(\"έ\", \"ε\").str.replace('ή','η').str.replace('ί','ι').str.replace('ό','ο').str.replace('ύ','υ').str.replace('ώ','ω')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpR74HXWzXLi"
      },
      "outputs": [],
      "source": [
        "text = Uk[Uk['year']==2022]['text'].str.cat(sep = '.').replace(\"amp\", ' ')\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwbmoH-vzZGC"
      },
      "outputs": [],
      "source": [
        "list(STOPWORDS)[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCX66T0ezcny"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "!python -m spacy download el_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD4tJrFXzh56"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('el_core_news_sm')\n",
        "list(nlp.Defaults.stop_words)[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ5U77Ljzjw6"
      },
      "outputs": [],
      "source": [
        "text = Uk['text'].str.cat(sep = '.').replace('.','').strip()\n",
        "text = text.replace('amp','').strip()\n",
        "text = text.replace('rt','').strip()\n",
        "text = text.replace('\\n','').strip()\n",
        "text = text.replace(':','').strip()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_ZEKzSMzoHT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o04U07lbzpv_"
      },
      "outputs": [],
      "source": [
        "doc = nlp(Uk['text'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwYRIkhSzsQg"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token, token.lemma_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWSGfzAozvT-"
      },
      "outputs": [],
      "source": [
        "' '.join(token.lemma_ for token in doc)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGCZ-joazxQg"
      },
      "outputs": [],
      "source": [
        "full_doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJhjd1zez0_3"
      },
      "outputs": [],
      "source": [
        "clear_text = ' '.join(token.lemma_ for token in full_doc)\n",
        "clear_text[200:400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKA6SyG3z4AR"
      },
      "outputs": [],
      "source": [
        "wordcloud = WordCloud(\n",
        "    stopwords = nlp.Defaults.stop_words,\n",
        "    width = 2000,\n",
        "    height = 1000,\n",
        "    background_color = 'yellow'\n",
        " ).generate(clear_text)\n",
        "fig = plt.figure(\n",
        "    figsize = (40, 30),\n",
        "    facecolor = 'k',\n",
        "    edgecolor = 'k')\n",
        "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "326_mZzpz4aC"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "Counter(\" \".join(Uk[\"text\"]).split()).most_common(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZWwhlAgz6hi"
      },
      "outputs": [],
      "source": [
        "for word in nlp.Defaults.stop_words:\n",
        "  print(word)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj5LxXAIz8kC"
      },
      "outputs": [],
      "source": [
        "Uk['text_no_stopwords'] = Uk['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (nlp.Defaults.stop_words) and word != ':' and word != '\\n' and word != \"amp\" and word != 'rt' and word != ',']))\n",
        "Uk['text_no_stopwords'] = Uk['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (nlp.Defaults.stop_words)]))\n",
        "Uk['clean_text_no_stopwords'] = Uk['text']\n",
        "#for stopword in nlp.Defaults.stop_words:\n",
        "Uk['clean_text_no_stopwords'] = Uk['clean_text_no_stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in nlp.Defaults.stop_words and word != \"ή\" and word != \"ία\" and word != \"κι\"]))\n",
        "Uk['clean_text_no_stopwords'] = Uk['clean_text_no_stopwords'].apply(lambda x: x.replace(\"amp\", \"\").strip())\n",
        "Uk['clean_text_no_stopwords'] = Uk['clean_text_no_stopwords'].apply(lambda x: x.replace(\"rt\", \"\").strip())\n",
        "Uk['clean_text_no_stopwords'] = Uk['clean_text_no_stopwords'].apply(lambda x: x.replace(\":\", \"\").strip())\n",
        "Uk['clean_text_no_stopwords'] = Uk['clean_text_no_stopwords'].apply(lambda x: x.replace(\",\", \"\").strip())\n",
        "Uk['clean_text_no_stopwords'] = Uk['clean_text_no_stopwords'].apply(lambda x: x.replace(\"\\n\", \"\").strip())\n",
        "Uk['clean_text_no_stopwords'] = Uk['clean_text_no_stopwords'].apply(lambda x: x.replace(\".\", \"\").strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfTPd2hfz-Zi"
      },
      "outputs": [],
      "source": [
        "freq = Counter(\" \".join(Uk[\"clean_text_no_stopwords\"]).split()).most_common(16)\n",
        "freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YwJ8bUx0DFF"
      },
      "outputs": [],
      "source": [
        "names, values = zip(*freq)\n",
        "# names = [x[0] for x in data]  # These two lines are equivalent to the the zip-command.\n",
        "# values = [x[1] for x in data] # These two lines are equivalent to the the zip-command.\n",
        "\n",
        "ind = np.arange(len(freq))  # the x locations for the groups\n",
        "width = 0.35       # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "rects1 = ax.bar(ind, values, width, color='r')\n",
        "# add some text for labels, title and axes ticks\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_xticks(ind+width/10.)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "def autolabel(rects):\n",
        "    # attach some text labels\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x() + rect.get_width()/2, height,\n",
        "                '%d' % int(height),\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqhDks7LuzRN"
      },
      "source": [
        "# Emolex Ουκρανία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRZ3H_N-u47n"
      },
      "outputs": [],
      "source": [
        "filepath = \"https://raw.githubusercontent.com/datajour-gr/Data_journalism/master/week10/NRC_GREEK_Translated_6_2020.csv\"\n",
        "emolex_df = pd.read_csv(filepath)\n",
        "emolex_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp1Ihff0u727"
      },
      "outputs": [],
      "source": [
        "emolex_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ellpFeI6vAU9"
      },
      "outputs": [],
      "source": [
        "emolex_df = emolex_df.drop_duplicates(subset=['word'])\n",
        "emolex_df = emolex_df.dropna()\n",
        "emolex_df.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etx1MpWHvDGv"
      },
      "outputs": [],
      "source": [
        "emolex_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHgRK_XAvIS0"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('el_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOqFsmwmvdwh"
      },
      "outputs": [],
      "source": [
        "len(Uk)\n",
        "Uk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJunCkQCvhyN"
      },
      "outputs": [],
      "source": [
        "#short_tweets_Ukr = Uk[['created_at','full_text' ]]\n",
        "#short_tweets_Ukr = short_tweets_Ukr.rename(columns={'created_at': 'date', 'full_text': 'text'} )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_9h8zwIvi_z"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr = Uk[['date','text' ]]\n",
        "\n",
        "short_tweets_Ukr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfpVy53Ivr7w"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86hSqevZvxNp"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz3QXXHdvzHX"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['date'] = pd.to_datetime(short_tweets_Ukr['date'], format='%a %b %d %H:%M:%S +0000 %Y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAbchJBQdudf"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['year'] = pd.DatetimeIndex(short_tweets_Ukr['date']).year\n",
        "short_tweets_Ukr['month'] = pd.DatetimeIndex(short_tweets_Ukr['date']).month\n",
        "short_tweets_Ukr['day'] = pd.DatetimeIndex(short_tweets_Ukr['date']).day\n",
        "short_tweets_Ukr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erd8VmilvzNf"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwWh-nrev8eQ"
      },
      "outputs": [],
      "source": [
        "emolex_df['word'].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DHrIug-wAYY"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['text'] = short_tweets_Ukr['text'].str.replace(r'https?:\\/\\/.*[\\r\\n]*',\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXdljq9AwFW1"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DUfpHfRwMhH"
      },
      "outputs": [],
      "source": [
        "vec = CountVectorizer(analyzer = 'word', vocabulary = emolex_df.word, \n",
        "                      strip_accents = 'unicode',  \n",
        "                      stop_words= nlp.Defaults.stop_words,\n",
        "                      ngram_range=(1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw6LCoL5wQO8"
      },
      "outputs": [],
      "source": [
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#CountVectorizer(stop_words='english', binary=True)\n",
        "# Θέλω να ελέγξω μόνο τις λέξεις που υπάρχουν στο συναισθηματικό λεξικό\n",
        "\n",
        "#CountVectorizer(analyzer = 'word', \n",
        "#              strip_accents = 'unicode', \n",
        "#               token_pattern='[Α-Ωα-ωΆ-Ώά-ώ]{2,}', \n",
        "#               stop_words= lc_stop_words_df['stop_w'].tolist())\n",
        "\n",
        "\n",
        "matrix = vec.fit_transform(short_tweets_Ukr['text'])\n",
        "vocab = vec.get_feature_names()\n",
        "wordcount_df = pd.DataFrame(matrix.toarray(), columns=vocab)\n",
        "wordcount_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2iocwNrwnWk"
      },
      "outputs": [],
      "source": [
        "wordcount_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRjRf1eIwoRx"
      },
      "outputs": [],
      "source": [
        "emolex_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5Wivr_EwsAo"
      },
      "outputs": [],
      "source": [
        "emolex_df[emolex_df.Anger == 1].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kT9vstpxmAJ"
      },
      "outputs": [],
      "source": [
        "# Φτιάξε μια λίστα με positive words\n",
        "\n",
        "angry_words = emolex_df[emolex_df.Anger == 1]['word']\n",
        "\n",
        "positive_words = emolex_df[emolex_df.Positive == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με sadness words\n",
        "sadness_words = emolex_df[emolex_df.Sadness == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με surprise words\n",
        "surprise_words = emolex_df[emolex_df.Surprise == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με disgust words\n",
        "disgust_words = emolex_df[emolex_df.Disgust == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με anticipation words\n",
        "anticipation_words = emolex_df[emolex_df.Anticipation == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με negative words\n",
        "negative_words = emolex_df[emolex_df.Negative == 1]['word']\n",
        "\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με joy words\n",
        "joy_words = emolex_df[emolex_df.Joy == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με trust words\n",
        "trust_words = emolex_df[emolex_df.Trust == 1]['word']\n",
        "\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με fear words\n",
        "fear_words = emolex_df[emolex_df.Fear == 1]['word']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iDwKkKyxn7p"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTXk2SXTxwkq"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['anger'] = wordcount_df[angry_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ukr['positivity'] = wordcount_df[positive_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ukr['joy'] = wordcount_df[joy_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ukr['disgust'] = wordcount_df[disgust_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ukr['surprise'] = wordcount_df[surprise_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ukr['trust'] = wordcount_df[trust_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ukr['anticipation'] = wordcount_df[anticipation_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ukr['sadness'] = wordcount_df[sadness_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ukr['negative'] = wordcount_df[negative_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ukr['fear'] = wordcount_df[fear_words].sum(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FymXwNRIx4tH"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0Vlf22bRFUd"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "happiest_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ukr)):\n",
        "  #print(short_tweets_Rus.iloc[i]['positivity'])\n",
        "  if short_tweets_Ukr.iloc[i]['positivity'] > max:\n",
        "    happiest_tweet = short_tweets_Ukr.iloc[i]['text']\n",
        "    max = short_tweets_Ukr.iloc[i]['positivity']\n",
        "\n",
        "\n",
        "happiest_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jxr9wiqRVIj"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "negative_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ukr)):\n",
        "  #print(short_tweets_Ukr.iloc[i]['positivity'])\n",
        "  if short_tweets_Ukr.iloc[i]['negative'] > max:\n",
        "    negative_tweet = short_tweets_Ukr.iloc[i]['text']\n",
        "    max = short_tweets_Ukr.iloc[i]['negative']\n",
        "\n",
        "\n",
        "negative_tweet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max = 0\n",
        "anger_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ukr)):\n",
        "  #print(short_tweets_Ukr.iloc[i]['positivity'])\n",
        "  if short_tweets_Ukr.iloc[i]['anger'] > max:\n",
        "    anger_tweet = short_tweets_Ukr.iloc[i]['text']\n",
        "    max = short_tweets_Ukr.iloc[i]['anger']\n",
        "\n",
        "anger_tweet"
      ],
      "metadata": {
        "id": "VeWpFNa_tVLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMpTZt3sRksr"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "saddest_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ukr)):\n",
        "  #print(short_tweets_Ukr.iloc[i]['positivity'])\n",
        "  if short_tweets_Ukr.iloc[i]['sadness'] > max:\n",
        "    saddest_tweet = short_tweets_Ukr.iloc[i]['text']\n",
        "    max = short_tweets_Ukr.iloc[i]['sadness']\n",
        "\n",
        "saddest_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlWoMd80SKRQ"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "fear_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ukr)):\n",
        "  #print(short_tweets_Ukr.iloc[i]['positivity'])\n",
        "  if short_tweets_Ukr.iloc[i]['fear'] > max:\n",
        "    fear_tweet = short_tweets_Ukr.iloc[i]['text']\n",
        "    max = short_tweets_Ukr.iloc[i]['fear']\n",
        "\n",
        "fear_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N-VVE6ZSX44"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "trust_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ukr)):\n",
        "  #print(short_tweets_Ukr.iloc[i]['positivity'])\n",
        "  if short_tweets_Ukr.iloc[i]['trust'] > max:\n",
        "    trust_tweet = short_tweets_Ukr.iloc[i]['text']\n",
        "    max = short_tweets_Ukr.iloc[i]['trust']\n",
        "\n",
        "trust_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvea9No6x8gY"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr.set_index('date' , inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMtpVOC4ylFG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKLAvWGPyIt2"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['text'].str.len().resample('D').mean().plot() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVhJYwqEyGvn"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['positivity'].resample('D').mean().plot() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OG2Cmu7byRxC"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['negative'].resample('D').sum().plot(color = 'b',label = 'neg').legend() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgtKz7OqyVSb"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['anger'].resample('D').sum().plot(figsize=(16,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kW8Dh4J6yo1Z"
      },
      "outputs": [],
      "source": [
        "ax = short_tweets_Ukr['positivity'].resample('D').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'g', label='pos')\n",
        "short_tweets_Ukr['negative'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg', color = 'r')\n",
        "short_tweets_Ukr['trust'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust',color = 'blue').legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJWr_97XQpom"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "ax = short_tweets_Ukr['positivity'].resample('D').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'g', label='pos')\n",
        "short_tweets_Ukr['negative'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg', color = 'r')\n",
        "short_tweets_Ukr['trust'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust',color = 'blue').legend()\n",
        "\n",
        "short_tweets_Ukr['disgust'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'disg',color = 'black').legend() \n",
        "\n",
        "short_tweets_Ukr['anger'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'anger',color = 'purple').legend() \n",
        "\n",
        "short_tweets_Ukr['fear'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'fear',color = 'brown').legend()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dQ-0RHhaIph"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ukr['text'].groupby(by=short_tweets_Ukr.index.hour).count().plot(kind='barh')\n",
        "plt.title(\"Posts per hour\")\n",
        "plt.xlabel(\"Number of posts\")\n",
        "plt.ylabel(\"Hour of the day\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDwa94VykUSD"
      },
      "source": [
        "#  #Ρωσία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XL7LIGwkUSD"
      },
      "outputs": [],
      "source": [
        "tweets = []\n",
        "MAX_ATTEMPTS = 50\n",
        "COUNT_OF_TWEETS_TO_BE_FETCHED = 10000 \n",
        "\n",
        "for i in range(0,MAX_ATTEMPTS):\n",
        "\n",
        "    if(COUNT_OF_TWEETS_TO_BE_FETCHED < len(tweets)):\n",
        "        print(\"We Got \", len(tweets), \" tweets!!!\")\n",
        "        break # we got the  tweets... !!\n",
        "\n",
        "    #----------------------------------------------------------------#\n",
        "    # STEP 1: Query Twitter\n",
        "    # STEP 2: Save the returned tweets\n",
        "    # STEP 3: Get the next max_id\n",
        "    #----------------------------------------------------------------#\n",
        "\n",
        "    # STEP 1: Query Twitter\n",
        "    if(0 == i):\n",
        "        # Query twitter for data. \n",
        "        results = twitter.search(q=\"Ρωσία\",count='100')\n",
        "        print(\"I Got:\", len(results['statuses']), \" tweets\")\n",
        "    else:\n",
        "        # After the first call we should have max_id from result of previous call. Pass it in query.\n",
        "        results = twitter.search(q=\"ρωσία\",count='100', include_entities='true',max_id=next_max_id)\n",
        "        print(\"I Got:\", len(results['statuses']), \" tweets\")\n",
        "\n",
        "\n",
        "    # STEP 2: Save the returned tweets\n",
        "    for result in results['statuses']:\n",
        "#        tweet_text = result['text']\n",
        "        tweets.append(result)\n",
        "\n",
        "\n",
        "    # STEP 3: Get the next max_id\n",
        "    try:\n",
        "        # Parse the data returned to get max_id to be passed in consequent call.\n",
        "        next_results_url_params = results['search_metadata']['next_results']\n",
        "        next_max_id = next_results_url_params.split('max_id=')[1].split('&')[0]\n",
        "    except:\n",
        "        # No more next pages\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSyk_DrskUSF"
      },
      "outputs": [],
      "source": [
        "#results['search_metadata']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5CHf8CokUSF"
      },
      "outputs": [],
      "source": [
        "#results['statuses']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIEu-6FjkUSG"
      },
      "outputs": [],
      "source": [
        "Ru_df = pd.DataFrame(tweets)\n",
        "Ru_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAQ0L6FMkUSG"
      },
      "outputs": [],
      "source": [
        "# Number of tweets the user has made\n",
        "print(\"I got :\", len(Ru_df), \" in total!!!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3gTWG_XkUSH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfgJBmODkUSH"
      },
      "outputs": [],
      "source": [
        "Ru_df.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/Ρωσία_tweet.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5In3qoWVknPR"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Nh34ijtkng9"
      },
      "source": [
        "# Νέα ενότητα #Ρωσία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ot5bBFkwkng9"
      },
      "outputs": [],
      "source": [
        "Ru_df =pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/Ρωσία_tweet.tsv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXZhmlVskng9"
      },
      "outputs": [],
      "source": [
        "Ru = Ru_df[['created_at','text' ]]\n",
        "Ru = Ru.rename(columns={'created_at': 'date'} )\n",
        "Ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P33p1LK1kng9"
      },
      "outputs": [],
      "source": [
        "#Ru.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9Kze8gCkng-"
      },
      "outputs": [],
      "source": [
        "Ru['year'] = pd.DatetimeIndex(Ru['date']).year\n",
        "Ru['month'] = pd.DatetimeIndex(Ru['date']).month\n",
        "Ru['day'] = pd.DatetimeIndex(Ru['date']).day\n",
        "Ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQdw-PQNkng-"
      },
      "outputs": [],
      "source": [
        "Ru['text'] = Ru['text'].str.replace(r'https?:\\/\\/.*[\\r\\n]*',\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RifOduwUkng-"
      },
      "outputs": [],
      "source": [
        "Ru['day'].value_counts().plot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNy6YmTdkng-"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDy3X9RKkng-"
      },
      "outputs": [],
      "source": [
        "Ru[Ru['year']==2022]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYFtjUQMkng-"
      },
      "outputs": [],
      "source": [
        "# Ισως καποτε χρειαστεί να αφαιρέσουμε τους τόνους.....\n",
        "text = Ru['text'].str.replace('ά','α').str.replace(\"έ\", \"ε\").str.replace('ή','η').str.replace('ί','ι').str.replace('ό','ο').str.replace('ύ','υ').str.replace('ώ','ω')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nmtfvlDkng-"
      },
      "outputs": [],
      "source": [
        "text = Ru[Ru['year']==2022]['text'].str.cat(sep = '.').replace(\"amp\", ' ')\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuqxuWEukng-"
      },
      "outputs": [],
      "source": [
        "list(STOPWORDS)[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C24NlCLCkng_"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "!python -m spacy download el_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncov4f-Tkng_"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('el_core_news_sm')\n",
        "list(nlp.Defaults.stop_words)[0:20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkFZ-mJikng_"
      },
      "outputs": [],
      "source": [
        "text = Ru['text'].str.cat(sep = '.').replace('.','').strip()\n",
        "text = text.replace('amp','').strip()\n",
        "text = text.replace('rt','').strip()\n",
        "text = text.replace('\\n','').strip()\n",
        "text = text.replace(':','').strip()\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjoRAtZPkng_"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl3QCx7Ukng_"
      },
      "outputs": [],
      "source": [
        "doc = nlp(Ru['text'][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWd61uSmkng_"
      },
      "outputs": [],
      "source": [
        "for token in doc:\n",
        "    print(token, token.lemma_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXGzko37knhA"
      },
      "outputs": [],
      "source": [
        "' '.join(token.lemma_ for token in doc)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8jclA3dknhA"
      },
      "outputs": [],
      "source": [
        "full_doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okQgqp3hknhA"
      },
      "outputs": [],
      "source": [
        "clear_text = ' '.join(token.lemma_ for token in full_doc)\n",
        "clear_text[200:400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "958NAaYLknhA"
      },
      "outputs": [],
      "source": [
        "wordcloud = WordCloud(\n",
        "    stopwords = nlp.Defaults.stop_words,\n",
        "    width = 2000,\n",
        "    height = 1000,\n",
        "    background_color = 'red'\n",
        " ).generate(clear_text)\n",
        "fig = plt.figure(\n",
        "    figsize = (40, 30),\n",
        "    facecolor = 'k',\n",
        "    edgecolor = 'k')\n",
        "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDIyD5htknhA"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "Counter(\" \".join(Ru[\"text\"]).split()).most_common(16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apcQ42DJknhA"
      },
      "outputs": [],
      "source": [
        "for word in nlp.Defaults.stop_words:\n",
        "  print(word)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qb_l3fwrknhA"
      },
      "outputs": [],
      "source": [
        "Ru['text_no_stopwords'] = Ru['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (nlp.Defaults.stop_words) and word != ':' and word != '\\n' and word != \"amp\" and word != 'rt' and word != ',']))\n",
        "Ru['text_no_stopwords'] = Ru['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (nlp.Defaults.stop_words)]))\n",
        "Ru['clean_text_no_stopwords'] = Ru['text']\n",
        "#for stopword in nlp.Defaults.stop_words:\n",
        "Ru['clean_text_no_stopwords'] = Ru['clean_text_no_stopwords'].apply(lambda x: ' '.join([word for word in x.split() if word not in nlp.Defaults.stop_words and word != \"ή\" and word != \"ία\" and word != \"κι\"]))\n",
        "Ru['clean_text_no_stopwords'] = Ru['clean_text_no_stopwords'].apply(lambda x: x.replace(\"amp\", \"\").strip())\n",
        "Ru['clean_text_no_stopwords'] = Ru['clean_text_no_stopwords'].apply(lambda x: x.replace(\"rt\", \"\").strip())\n",
        "Ru['clean_text_no_stopwords'] = Ru['clean_text_no_stopwords'].apply(lambda x: x.replace(\":\", \"\").strip())\n",
        "Ru['clean_text_no_stopwords'] = Ru['clean_text_no_stopwords'].apply(lambda x: x.replace(\",\", \"\").strip())\n",
        "Ru['clean_text_no_stopwords'] = Ru['clean_text_no_stopwords'].apply(lambda x: x.replace(\"\\n\", \"\").strip())\n",
        "Ru['clean_text_no_stopwords'] = Ru['clean_text_no_stopwords'].apply(lambda x: x.replace(\".\", \"\").strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCvJrBx4knhB"
      },
      "outputs": [],
      "source": [
        "freq = Counter(\" \".join(Ru[\"clean_text_no_stopwords\"]).split()).most_common(16)\n",
        "freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWCcmI7lknhB"
      },
      "outputs": [],
      "source": [
        "names, values = zip(*freq)\n",
        "# names = [x[0] for x in data]  # These two lines are equivalent to the the zip-command.\n",
        "# values = [x[1] for x in data] # These two lines are equivalent to the the zip-command.\n",
        "\n",
        "ind = np.arange(len(freq))  # the x locations for the groups\n",
        "width = 0.35       # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20,5))\n",
        "rects1 = ax.bar(ind, values, width, color='r')\n",
        "# add some text for labels, title and axes ticks\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_xticks(ind+width/10.)\n",
        "ax.set_xticklabels(names)\n",
        "\n",
        "def autolabel(rects):\n",
        "    # attach some text labels\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.text(rect.get_x() + rect.get_width()/2, height,\n",
        "                '%d' % int(height),\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frqXzJAOllCq"
      },
      "source": [
        "# Emolex Ρωσία"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfITXPujllCr"
      },
      "outputs": [],
      "source": [
        "filepath = \"https://raw.githubusercontent.com/datajour-gr/Data_journalism/master/week10/NRC_GREEK_Translated_6_2020.csv\"\n",
        "emolex_df = pd.read_csv(filepath)\n",
        "emolex_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m6zPuQdnllCr"
      },
      "outputs": [],
      "source": [
        "emolex_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "St1A45pKllCr"
      },
      "outputs": [],
      "source": [
        "emolex_df = emolex_df.drop_duplicates(subset=['word'])\n",
        "emolex_df = emolex_df.dropna()\n",
        "emolex_df.reset_index(drop = True, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaTGgrzsllCr"
      },
      "outputs": [],
      "source": [
        "emolex_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbG7ultHllCr"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('el_core_news_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33zzqlvillCs"
      },
      "outputs": [],
      "source": [
        "len(Ru)\n",
        "Ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "an-SUWyollCs"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru = Ru[['date','text' ]]\n",
        "\n",
        "short_tweets_Ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RDJAahillCs"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDcUHw4PllCs"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1O4rkUCllCs"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['date'] = pd.to_datetime(short_tweets_Ru['date'], format='%a %b %d %H:%M:%S +0000 %Y')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbTsEAZ0llCs"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['year'] = pd.DatetimeIndex(short_tweets_Ru['date']).year\n",
        "short_tweets_Ru['month'] = pd.DatetimeIndex(short_tweets_Ru['date']).month\n",
        "short_tweets_Ru['day'] = pd.DatetimeIndex(short_tweets_Ru['date']).day\n",
        "short_tweets_Ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvHvtq25llCt"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyBnNw2XllCt"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4i1xVkyllCt"
      },
      "outputs": [],
      "source": [
        "emolex_df['word'].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF31pNaIllCt"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['text'] = short_tweets_Ru['text'].str.replace(r'https?:\\/\\/.*[\\r\\n]*',\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrgcSOL3llCt"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FANjm6-NllCt"
      },
      "outputs": [],
      "source": [
        "vec = CountVectorizer(analyzer = 'word', vocabulary = emolex_df.word, \n",
        "                      strip_accents = 'unicode',  \n",
        "                      stop_words= nlp.Defaults.stop_words,\n",
        "                      ngram_range=(1, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bPARFfmllCt"
      },
      "outputs": [],
      "source": [
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#CountVectorizer(stop_words='english', binary=True)\n",
        "# Θέλω να ελέγξω μόνο τις λέξεις που υπάρχουν στο συναισθηματικό λεξικό\n",
        "\n",
        "#CountVectorizer(analyzer = 'word', \n",
        "#              strip_accents = 'unicode', \n",
        "#               token_pattern='[Α-Ωα-ωΆ-Ώά-ώ]{2,}', \n",
        "#               stop_words= lc_stop_words_df['stop_w'].tolist())\n",
        "\n",
        "\n",
        "matrix = vec.fit_transform(short_tweets_Ru['text'])\n",
        "vocab = vec.get_feature_names()\n",
        "wordcount_df = pd.DataFrame(matrix.toarray(), columns=vocab)\n",
        "wordcount_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8Y3Wq5vllCu"
      },
      "outputs": [],
      "source": [
        "wordcount_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgXjMsBxllCu"
      },
      "outputs": [],
      "source": [
        "emolex_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Si7sRlTllCu"
      },
      "outputs": [],
      "source": [
        "emolex_df[emolex_df.Anger == 1].tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc8sjPJillCu"
      },
      "outputs": [],
      "source": [
        "# Φτιάξε μια λίστα με positive words\n",
        "\n",
        "angry_words = emolex_df[emolex_df.Anger == 1]['word']\n",
        "\n",
        "positive_words = emolex_df[emolex_df.Positive == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με sadness words\n",
        "sadness_words = emolex_df[emolex_df.Sadness == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με surprise words\n",
        "surprise_words = emolex_df[emolex_df.Surprise == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με disgust words\n",
        "disgust_words = emolex_df[emolex_df.Disgust == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με anticipation words\n",
        "anticipation_words = emolex_df[emolex_df.Anticipation == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με negative words\n",
        "negative_words = emolex_df[emolex_df.Negative == 1]['word']\n",
        "\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με joy words\n",
        "joy_words = emolex_df[emolex_df.Joy == 1]['word']\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με trust words\n",
        "trust_words = emolex_df[emolex_df.Trust == 1]['word']\n",
        "\n",
        "\n",
        "\n",
        "# Φτιάξε μια λίστα με fear words\n",
        "fear_words = emolex_df[emolex_df.Fear == 1]['word']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tR6TmbZlllCu"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmKXSP1kllCu"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['anger'] = wordcount_df[angry_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ru['positivity'] = wordcount_df[positive_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ru['joy'] = wordcount_df[joy_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ru['disgust'] = wordcount_df[disgust_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ru['surprise'] = wordcount_df[surprise_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ru['trust'] = wordcount_df[trust_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ru['anticipation'] = wordcount_df[anticipation_words].sum(axis=1)\n",
        "\n",
        "\n",
        "short_tweets_Ru['sadness'] = wordcount_df[sadness_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ru['negative'] = wordcount_df[negative_words].sum(axis=1)\n",
        "\n",
        "short_tweets_Ru['fear'] = wordcount_df[fear_words].sum(axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4ZWn9vFllCu"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0nbiH2jllCv"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "happiest_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ru)):\n",
        "  #print(short_tweets_Ru.iloc[i]['positivity'])\n",
        "  if short_tweets_Ru.iloc[i]['positivity'] > max:\n",
        "    happiest_tweet = short_tweets_Ru.iloc[i]['text']\n",
        "    max = short_tweets_Ru.iloc[i]['positivity']\n",
        "\n",
        "\n",
        "happiest_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_M7xZaKllCv"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "negative_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ru)):\n",
        "  #print(short_tweets_Ru.iloc[i]['positivity'])\n",
        "  if short_tweets_Ru.iloc[i]['negative'] > max:\n",
        "    negative_tweet = short_tweets_Ru.iloc[i]['text']\n",
        "    max = short_tweets_Ru.iloc[i]['negative']\n",
        "\n",
        "\n",
        "negative_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk4_jVjHllCv"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "saddest_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ru)):\n",
        "  #print(short_tweets_Ru.iloc[i]['positivity'])\n",
        "  if short_tweets_Ru.iloc[i]['sadness'] > max:\n",
        "    saddest_tweet = short_tweets_Ru.iloc[i]['text']\n",
        "    max = short_tweets_Ru.iloc[i]['sadness']\n",
        "\n",
        "saddest_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjLV4MYzllCv"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "fear_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ru)):\n",
        "  #print(short_tweets_Ru.iloc[i]['positivity'])\n",
        "  if short_tweets_Ru.iloc[i]['fear'] > max:\n",
        "    fear_tweet = short_tweets_Ru.iloc[i]['text']\n",
        "    max = short_tweets_Ru.iloc[i]['fear']\n",
        "\n",
        "fear_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kYHgp_9llCv"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "trust_tweet = \"\"\n",
        "for i in range(0,len(short_tweets_Ru)):\n",
        "  #print(short_tweets_Ru.iloc[i]['positivity'])\n",
        "  if short_tweets_Ru.iloc[i]['trust'] > max:\n",
        "    trust_tweet = short_tweets_Ru.iloc[i]['text']\n",
        "    max = short_tweets_Ru.iloc[i]['trust']\n",
        "\n",
        "trust_tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPg_Gvh8llCv"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru.set_index('date' , inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIQUQLmlllCv"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFSPNsgMllCw"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['text'].str.len().groupby(by=short_tweets_Ru.index.month).mean().plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5CAYZLpllCw"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['text'].str.len().resample('D').mean().plot() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UB50dvrsllCw"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['positivity'].resample('D').mean().plot() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y7Yx2MODllCw"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['negative'].resample('D').sum().plot(color = 'b',label = 'neg').legend() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUg_1ZpsllCw"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['anger'].resample('D').sum().plot(figsize=(16,4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2lbxwzxllCx"
      },
      "outputs": [],
      "source": [
        "ax = short_tweets_Ru['positivity'].resample('D').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'g', label='pos')\n",
        "short_tweets_Ru['negative'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg', color = 'r')\n",
        "short_tweets_Ru['trust'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust',color = 'blue').legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TalU0xkGllCx"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "ax = short_tweets_Ru['positivity'].resample('D').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'g', label='pos')\n",
        "short_tweets_Ru['negative'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg', color = 'r')\n",
        "short_tweets_Ru['trust'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust',color = 'blue').legend()\n",
        "\n",
        "short_tweets_Ru['disgust'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'disg',color = 'black').legend() \n",
        "\n",
        "short_tweets_Ru['anger'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'anger',color = 'purple').legend() \n",
        "\n",
        "short_tweets_Ru['fear'].resample('D').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'fear',color = 'brown').legend()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esTsW5PUllCx"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru['text'].groupby(by=short_tweets_Ru.index.hour).count().plot(kind='barh')\n",
        "plt.title(\"Posts per hour\")\n",
        "plt.xlabel(\"Number of posts\")\n",
        "plt.ylabel(\"Hour of the day\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PodfW99Vavl2"
      },
      "outputs": [],
      "source": [
        "short_tweets_Ru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__73lPL3Q1V3"
      },
      "source": [
        "# Rudf - Ukdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBUM9i4rTG1S"
      },
      "outputs": [],
      "source": [
        "ax = short_tweets_Ru['positivity'].resample('B').sum().plot(figsize=(16,4), color = 'red')\n",
        "short_tweets_Ru['negative'].resample('B').sum().plot(figsize=(16,4), ax = ax, color = 'green')\n",
        "short_tweets_Ru['trust'].resample('B').sum().plot(figsize=(16,4), ax = ax, color = 'blue')\n",
        "ax = short_tweets_Ukr['positivity'].resample('B').sum().plot(figsize=(16,4), color = 'yellow')\n",
        "short_tweets_Ukr['negative'].resample('B').sum().plot(figsize=(16,4), ax = ax, color = 'purple')\n",
        "short_tweets_Ukr['trust'].resample('B').sum().plot(figsize=(16,4), ax = ax, color = 'orange')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h5g1daeTYX6"
      },
      "outputs": [],
      "source": [
        "ax = short_tweets_Ru['positivity'].resample('B').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'g', label='pos Ru')\n",
        "ax = short_tweets_Ukr['positivity'].resample('B').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'y', label='pos Uk')\n",
        "short_tweets_Ru['negative'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg Ru', color = 'r')\n",
        "short_tweets_Ukr['negative'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg Uk', color = 'purple')\n",
        "short_tweets_Ru['trust'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust Ru',color = 'blue').legend()\n",
        "short_tweets_Ukr['trust'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust Uk',color = 'orange').legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG8_qQOpUOpj"
      },
      "outputs": [],
      "source": [
        "plt.style.use('ggplot')\n",
        "ax = short_tweets_Ru['fear'].resample('B').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'g', label='pos Ru')\n",
        "short_tweets_Ru['anger'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg Ru', color = 'r')\n",
        "short_tweets_Ru['disgust'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust Ru',color = 'blue').legend()    \n",
        "short_tweets_Ukr['fear'].resample('B').mean().plot(figsize=(16,4), \n",
        "                                                          color = 'yellow', label='pos Uk')\n",
        "short_tweets_Ukr['anger'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                   label = 'neg Uk', color = 'orange')\n",
        "short_tweets_Ukr['disgust'].resample('B').mean().plot(figsize=(16,4), ax = ax, \n",
        "                                                label = 'trust Uk',color = 'purple').legend()                                                "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "96POgbJ3kNWk",
        "SaYGb8jQyybA",
        "jHMyxH3JqJLl",
        "NqhDks7LuzRN",
        "BDwa94VykUSD",
        "0Nh34ijtkng9",
        "mqpN5bRFlRew",
        "frqXzJAOllCq"
      ],
      "name": "Ukraine_Russia_hashtag1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}